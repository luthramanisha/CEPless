constants {
  default-load = 1.0
  default-request-timeout = 15 // s, used for load/bandwidth/etc requests
  coordinates-refresh-interval = 10
  coordinate-request-timeout = 15
  coordinates-error-threshold = 4.0
  transition-execution-mode = 1 # Can be 0 for "Sequential" or 1 for "Concurrent"
  event-interval-millis = 1000
  event-interval-nano = 1000000
  default-data-rate = 30 # Mbit/s Default data rate to use when there is no measurement yet
  data-rate-refresh-interval = 240
  simulation-time = 30
  gui-endpoint = "http://gui:3000"
  host-ip-addresses = ["128.112.170.35", "128.112.170.40", "128.112.170.36", "128.112.170.37", "128.112.170.38", "128.112.170.41", "128.112.170.39", "128.112.170.34"]
  minimum-number-of-nodes = 1 // set by manifest_to_config.py
  global-initialization-timeout = 60000 // ms

  // the MAPEK-Implementation controlling transitions to use
  // CONTRAST: make transitions according to performance predictions based on context information
  //    - a context-feature model (CFM) captures information about the context and system state
  //    - predictions are based on the current CFM configuration, which serves as input for a  Multiple Linear Regression model (learned with SPLConqueror)
  //    -  when choosing which placement algorithm to transit to, predictions for the respective metric are taken into account if QoS requirements exist
  //    - triggers for execution: QoS requirement change, context changes (checked periodically)
  // requirementBased: make transition based on QoS requirements (see benchmark configuration section)
  //    - triggers for execution: QoS requirement changes, nodes being shut down or started
  mapek {
    type = "requirementBased" // values: "requirementBased", "CONTRAST"
    sampling-interval = 5 // s
    transition-cooldown = 30 // s; time that must have passed before allowing another transition -> avoid oscillating transitions
    improvement-threshold = 0.0 // percentage of predicted metric improvement over current value that is necessary to allow a transition -> take predicition inaccuracy into account when making transition decision
    blacklisted-algorithms = ["fsRandom", "fsMobilityTolerant"]
  }

  placement {
    placement-request-timeout = 30 // s
    physical-placement-node-overload-threshold = 3.0 // unix cpu load level at which a node is considered overloaded
    physical-placement-nearest-neighbours = 3
    relaxation-initial-step-size = 0.1
    relaxation-step-adjustment-enabled = true // does not work well (overflows, oscillations) without stepsize adjustment
    max-single-operator-iterations = 200
    relaxation-initial-iterations = 30
    update-interval = 60 // seconds after which node re-evaluates its own operator's placement
    update { // enable or disable placement update functionality
      relaxation = false
      rizou = false
      starks = false
    }
  }
}

benchmark {
  general {
    algorithms = [
      "Relaxation",
      "MDCEP",
      //"Rizou",
      "ProducerConsumer",
      "Random",
      "GlobalOptimalBDPAlgorithm"]
  }

  Relaxation {
    optimizationCriteria = ["latency", "machineLoad"]
    constraints = ["LowChurnRate"]
    class = "tcep.placement.sbon.PietzuchAlgorithm$"
    score = 100
  }

  MDCEP {
    optimizationCriteria = ["messageHops", "machineLoad"]
    constraints = ["LowChurnRate"]
    class = "tcep.placement.manets.StarksAlgorithm$"
    score = 100
  }

  //Rizou {
  //  optimizationCriteria = ["machineLoad"] # does optimize for latency as well, but Relaxation has the same criteria -> make both selectable in RequirementBasedMAPEK via requirement change
  //  constraints = ["LowChurnRate"]
  //  class = "tcep.placement.mop.RizouAlgorithm$"
  //  score = 100
  //}

  ProducerConsumer {
    optimizationCriteria = ["messageHops"]
    constraints = ["HighChurnRate"]
    class = "tcep.placement.MobilityTolerantAlgorithm$"
    score = 200
  }

  Random {
    optimizationCriteria = []
    constraints = ["LowChurnRate"]
    class = "tcep.placement.RandomAlgorithm$"
    score = 200
  }

  GlobalOptimalBDPAlgorithm {
    optimizationCriteria = ["latency", "messageHops"]
    constraints = ["LowChurnRate"]
    class = "tcep.placement.GlobalOptimalBDPAlgorithm$"
    score = 100
  }
}

# define prio mailbox to be passed in Props of new actors that handle messages of differing priority
prio-mailbox {
  mailbox-type = "tcep.akkamailbox.TCEPPriorityMailbox"
}

akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 30s
  jvm-exit-on-fatal-error = false

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is usved by the LoggingAdapter before
  # publishing log events to the eventStream.
  # logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  log-config-on-start = off

  actor {

    provider = "cluster"
    timeout = 60000

    allow-java-serializer-usage = false // disable java serialization to ensure kryo is always used
    warn-about-java-serializer-usage = true
    serializers {
      java = "akka.serialization.JavaSerializer"
      # Define kryo serializer
      kryo = "com.twitter.chill.akka.AkkaSerializer"
    }

    # assign a mailbox type (prio-mailbox) to all actors with the name "TaskManager" and "DistVivaldiRef", even without specifying the mailbox in the Props
    deployment {
      /TaskManager {
        mailbox = prio-mailbox
      }
      /DistVivaldiRef {
        mailbox = prio-mailbox
      }
    }

    serialization-bindings {

      "java.io.Serializable" = kryo
      #"tcep.data.Events$" = kryo
      "tcep.data.Events$Event" = kryo
      "tcep.machinenodes.helper.actors.Message" = kryo
    }
  }
  remote {
    # If this is "on", Akka will log all outbound messages at DEBUG level,
    # if off then they are not logged
    log-sent-messages = off
    maximum-payload-bytes = 30000000 bytes

    netty.tcp {
      bind-hostname = "0.0.0.0"
      message-frame-size = 30000000b
      send-buffer-size = 30000000b
      receive-buffer-size = 30000000b
      maximum-frame-size = 30000000b
    }
  }

  cluster {
    seed-nodes = [
      #Names will be resolved by Docker Network. See publish_docker.sh for more details.
      "akka.tcp://tcep@viv:2549"]
  }
}

clustering {
  cluster.name = tcep
}

simulation {
  host = "subs"
  port = "2561"
}

# Disable legacy metrics in akka-cluster.
akka.cluster.metrics.enabled = off

# Enable metrics extension in akka-cluster-metrics.
akka.extensions = ["akka.cluster.metrics.ClusterMetricsExtension"]

# Sigar native library extract location during tests.
# Note: use per-jvm-instance folder when running multiple jvm on one host.
akka.cluster.metrics.native-library-extract-folder = ${user.dir}/target/native